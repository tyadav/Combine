{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required packages \n",
    "import pandas as pd\n",
    "import os \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all the paths for a particular file name. Checks all the directories and sub-directories \n",
    "\n",
    "def get_paths(folder_name,file_name):\n",
    "    \n",
    "    path = \"C:/Users/TejYadav/Desktop/ML Classification Package/V codes/Data Files for Machine Learning/\"+(folder_name)+\"/\"\n",
    "\n",
    "    all_paths = []\n",
    "    \n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if (file_name) in file:\n",
    "                all_paths.append(os.path.join(r, file))\n",
    "   \n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate new column names in case of multiple files with same attribute - format : filename_attributename\n",
    "\n",
    "def new_columns(fname,cnames):\n",
    "    new_cnames = []\n",
    "    for i in cnames:\n",
    "        new_cnames.append(fname+\"_\"+i)\n",
    "    return new_cnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate the output file for a particular file name present in a folder named folder name and extract attributes defined by \n",
    "# attribute name \n",
    "\n",
    "# output file format - main_dir_path + sheet_dir_path + input_file_name.csv\n",
    "def generate_file(folder_name,file_names,attribute_name,input_name):\n",
    "    \n",
    "    dframe_file = pd.DataFrame()\n",
    "    output_dframe = pd.DataFrame()\n",
    "    \n",
    "    attribute_name = attribute_name.encode('utf-8')\n",
    "    attribute_name = attribute_name.strip()\n",
    "    attribute_names = attribute_name.split(\"\\n\")\n",
    "    \n",
    "        \n",
    "    for fname in file_names:\n",
    "        all_paths_files = get_paths(folder_name,fname)   # get all possible paths for a folder and file name\n",
    "        \n",
    "        if len(file_names)>1:\n",
    "            temp_fname = fname.replace(\".csv\",\"\")\n",
    "            new_attribute_names = new_columns(temp_fname,attribute_names)  # get attributes as file_name_attribute_name for multiple files with same attribute names\n",
    "\n",
    "        for j in range(len(all_paths_files)):  \n",
    "            dframe = pd.read_csv(all_paths_files[j])\n",
    "            \n",
    "            if j == 0:\n",
    "                    dframe_file = dframe.loc[:,attribute_names]\n",
    "\n",
    "                    if len(file_names)>1:\n",
    "                        dframe_file.columns = new_attribute_names\n",
    "            else:\n",
    "                # append to same data frame for multiple files available with different dates\n",
    "                \n",
    "                temp_df = dframe.loc[:,attribute_names] \n",
    "                if len(file_names)>1:\n",
    "                    temp_df.columns = new_attribute_names\n",
    "                dframe_file=dframe_file.append(temp_df,ignore_index=True)\n",
    "        \n",
    "        output_dframe = pd.concat([output_dframe,dframe_file],axis=1)\n",
    "        \n",
    "    return output_dframe    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that uses other functions to extract all the attributes and stores output data frame corresponding to each sheet \n",
    "# in a list\n",
    "\n",
    "def extract_cols(sheets,output_dataframes_list):\n",
    " #   global main_dir_path\n",
    "    for sheet_name in sheets:\n",
    "        print(sheet_name)\n",
    "        \n",
    "        if str(sheet_name) != \"System Pump2\":\n",
    "            \n",
    "            dframe_sheet = pd.read_excel(xls,sheetname=sheet_name)\n",
    "            records,cols = (dframe_sheet.shape)\n",
    "            \n",
    "            dframe_for_each_sheet = pd.DataFrame()\n",
    "            result_df = pd.DataFrame()\n",
    "            \n",
    "            for i in range(0,records):\n",
    "                \n",
    "                folder_name = str(dframe_sheet.loc[i,'Folder Name'])\n",
    "                file_name = str(dframe_sheet.loc[i,'File Name'])\n",
    "                file_names = file_name.split(\"\\n\")\n",
    "                attribute_name = (dframe_sheet.loc[i,'Column Name'])\n",
    "                input_name = str(dframe_sheet.loc[i,'Inputs'])\n",
    "                if isinstance(attribute_name, unicode):\n",
    "                \n",
    "                    result_df = generate_file(folder_name,file_names,attribute_name,input_name) # returns for each file name in a sheet\n",
    "                \n",
    "                    dframe_for_each_sheet = pd.concat([dframe_for_each_sheet,result_df],axis=1) # concat acc to each sheet\n",
    "                    \n",
    "            final_records,final_cols=(dframe_for_each_sheet.shape)\n",
    "            \n",
    "            output_dataframes_list.append(dframe_for_each_sheet)  # appending to output list\n",
    "            \n",
    "            print(\"Number of attributes in the sheet : \"+str(final_cols))\n",
    "\n",
    "        elif str(sheet_name) == \"System Pump2\":\n",
    "            \n",
    "            dframe_sheet = pd.read_excel(xls,sheetname=sheet_name)\n",
    "            dframe_for_each_sheet = pd.DataFrame()\n",
    "            result_df = pd.DataFrame()\n",
    "            \n",
    "            records,cols = (dframe_sheet.shape)\n",
    "            \n",
    "            for i in range(0,10):\n",
    "               \n",
    "                folder_name = str(dframe_sheet.loc[i,'Folder Name'])\n",
    "                file_name = str(dframe_sheet.loc[i,'File Name'])\n",
    "                file_names = file_name.split(\"\\n\")\n",
    "                attribute_name = (dframe_sheet.loc[i,'Column Name'])\n",
    "                \n",
    "                if isinstance(attribute_name, unicode) and folder_name != ' ' and folder_name != 'nan' and file_name != ' ' and file_name != 'nan':\n",
    "                    result_df = generate_file(folder_name,file_names,attribute_name,input_name)\n",
    "                    dframe_for_each_sheet = pd.concat([dframe_for_each_sheet,result_df],axis=1)\n",
    "                   \n",
    "            # To consider these 15 files for each of the inputs \n",
    "            \n",
    "            system_pump_file_names = ['crah_server1_A_1.csv', 'crah_server1_A_2.csv', 'crah_server1_A_3.csv', 'crah_server1_A_4.csv',\n",
    "                                    'crah_server1_B_1.csv', 'crah_server1_B_2.csv', 'crah_server1_B_3.csv', 'crah_server1_B_4.csv', 'crah_storage1_A_1.csv', 'crah_storage1_B_1.csv',\n",
    "                                    'crah_ups_A_1.csv', 'crah_ups_A_2', 'crah_ups_B_1.csv', 'crah_ups_B_2.csv', 'crah_wan1_A_1.csv']\n",
    "            \n",
    "            for i in range(10,records):\n",
    "               \n",
    "                folder_name = str(dframe_sheet.loc[i,'Folder Name'])\n",
    "                file_name = str(dframe_sheet.loc[i,'File Name'])\n",
    "                file_names = file_name.split(\"\\n\")\n",
    "                attribute_name = (dframe_sheet.loc[i,'Column Name'])\n",
    "                input_name = str(dframe_sheet.loc[i,'Inputs'])\n",
    "                \n",
    "                if file_name != 'nan' and folder_name != 'nan' and file_name != ' ' and folder_name != ' ' and isinstance(attribute_name,unicode) :\n",
    "                    data_available = True\n",
    "                    result_df = generate_file(folder_name,system_pump_file_names,attribute_name,input_name) # returns for each file name in a sheet\n",
    "                    dframe_for_each_sheet = pd.concat([dframe_for_each_sheet,result_df],axis=1)  # concat acc to each sheet\n",
    "                \n",
    "            final_records,final_cols=(dframe_for_each_sheet.shape)\n",
    "            \n",
    "            output_dataframes_list.append(dframe_for_each_sheet) # appending to output list\n",
    "            \n",
    "            print(\"Number of attributes in the sheet : \"+str(final_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read input xlsx file - input workbook - Extract file.xlsx\n",
    "input_file_path = 'C:/Users/TejYadav/Desktop/ML Classification Package/V codes/WIP_V2.0.xlsx'  # Path to input file \n",
    "xls = pd.ExcelFile(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Condenser Pump', u'Evaporator Pump', u'System pump2', u'System Pump', u'Cooling Tower', u'Compression Chiller', u'CRAH', u'Overall Data Center Energy Flow']\n"
     ]
    }
   ],
   "source": [
    "# Getting names of all the worksheets from input workbook \n",
    "\n",
    "all_sheet_names = xls.sheet_names\n",
    "\n",
    "print(all_sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condenser Pump\n",
      "Number of attributes in the sheet : 13\n",
      "Evaporator Pump\n",
      "Number of attributes in the sheet : 12\n",
      "System pump2\n",
      "Number of attributes in the sheet : 6\n",
      "System Pump\n",
      "Number of attributes in the sheet : 0\n",
      "Cooling Tower\n",
      "Number of attributes in the sheet : 9\n",
      "Compression Chiller\n",
      "Number of attributes in the sheet : 0\n",
      "CRAH\n",
      "Number of attributes in the sheet : 0\n",
      "Overall Data Center Energy Flow\n",
      "Number of attributes in the sheet : 0\n"
     ]
    }
   ],
   "source": [
    "# Calling function for considering all the sheets in the input workbook\n",
    "output_dataframes_list = []    # list of data frames according to number of sheets \n",
    "extract_cols(all_sheet_names,output_dataframes_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to output file !\n",
      "File saved successfully !\n"
     ]
    }
   ],
   "source": [
    "# Writing the data corresponding to each sheet in xlsx file named output.xlsx - gets saved on desktop. \n",
    "print(\"Writing to output file !\")\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "output_file_path = 'C:/Users/TejYadav/Desktop/output.xlsx'  # output file path \n",
    "writer = pd.ExcelWriter(output_file_path, engine = 'openpyxl')\n",
    "\n",
    "for i in range(len(all_sheet_names)):\n",
    "    output_dataframes_list[i].to_excel(writer,sheet_name=all_sheet_names[i],encoding='utf-8',index = False)\n",
    "\n",
    "writer.save()\n",
    "writer.close()\n",
    "print(\"File saved successfully !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
